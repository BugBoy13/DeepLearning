{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "import xml.etree.cElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from future.utils import python_2_unicode_compatible\n",
    "from six.moves import cPickle as pickle\n",
    "from xml.dom import minidom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolo:\n",
    "    \n",
    "    numOfClasses = 20\n",
    "    \n",
    "    classes = [\n",
    "        \"aeroplane\",\n",
    "        \"bicycle\",\n",
    "        \"bird\",\n",
    "        \"boat\",\n",
    "        \"bottle\",\n",
    "        \"bus\",\n",
    "        \"car\",\n",
    "        \"cat\",\n",
    "        \"chair\",\n",
    "        \"cow\",\n",
    "        \"diningtable\",\n",
    "        \"dog\",\n",
    "        \"horse\",\n",
    "        \"motorbike\",\n",
    "        \"person\",\n",
    "        \"pottedplant\",\n",
    "        \"sheep\",\n",
    "        \"sofa\",\n",
    "        \"train\",\n",
    "        \"tvmonitor\"\n",
    "    ]\n",
    "    \n",
    "    # bounding box seeds\n",
    "    seed = [random.randint(1, 1000) for i in range(3)]\n",
    "    \n",
    "    def __init__(self,\n",
    "                 mode='testLive',\n",
    "                 weightFile='weights/YOLO_small.ckpt',\n",
    "                 showImage=True,\n",
    "                 saveAnnotatedImage=None,\n",
    "                 saveAnnotatedXML=None,\n",
    "                 numOfGridsIn1D=7,\n",
    "                 numOfBoxesPerGrid=2,\n",
    "                 batchSize=64,\n",
    "                 verbose=False,\n",
    "                 debug=False,\n",
    "                 minClassProbability=0.2,\n",
    "                 iouThreshold=0.5,\n",
    "                 lambdaCoordinate=5.0,\n",
    "                 lambdaNoObject=0.5,\n",
    "                 leakyReLUAlpha=0.1,\n",
    "                 inputFile='test/video1.mp4',\n",
    "                 outputFile='test/output.jpg',\n",
    "                 textOutputFile=None,\n",
    "                 inputFolder=None,\n",
    "                 outputFolder=None,\n",
    "                 textOutputFolder=None):\n",
    "        \n",
    "        # Mode to run the Yolo code in\n",
    "        # {testLive, testFile, testDB, testVideo, train}\n",
    "        self.mode = mode\n",
    "        \n",
    "        # Weights file\n",
    "        self.weightFile = weightFile\n",
    "        if not os.path.exists(self.weightFile):\n",
    "            print(\"ERROR: Weight file not found!! (or wrong)\")\n",
    "            return\n",
    "        \n",
    "        # To save annotated images\n",
    "        self.saveAnnotatedImage = saveAnnotatedImage\n",
    "        # To save annotated XML\n",
    "        self.saveAnnotatedXML = saveAnnotatedXML\n",
    "        \n",
    "        # To show images\n",
    "        self.showImage = showImage\n",
    "        # Number of grids in each dimension to divide image into\n",
    "        self.numOfGridsIn1D = numOfGridsIn1D\n",
    "        # Number of bounding boxes per grid\n",
    "        self.numOfBoxesPerGrid = numOfBoxesPerGrid\n",
    "        # Batch size during training\n",
    "        self.batchSize = batchSize\n",
    "        # To display logs of the program\n",
    "        self.verbose = verbose\n",
    "        # To display debug logs of the program\n",
    "        self.debug = debug\n",
    "        \n",
    "         # Used to disregard bounding boxes\n",
    "        self.minClassProbability = minClassProbability\n",
    "        # Used for non-maximum supression\n",
    "        self.iouThreshold = iouThreshold\n",
    "        # Used to increase contribution of localisation in the error pipeline\n",
    "        self.lambdaCoordinate = lambdaCoordinate\n",
    "        # Used to decrease contribution of cells which do not contain an object\n",
    "        self.lambdaNoObject = lambdaNoObject\n",
    "        # Parameter for leaky relu\n",
    "        self.leakyReLUAlpha = leakyReLUAlpha\n",
    "        \n",
    "        # Input file\n",
    "        self.inputFile = inputFile\n",
    "        # Output file\n",
    "        self.outputFile = outputFile\n",
    "        # textOutputFile file\n",
    "        self.textOutputFile = textOutputFile\n",
    "        # inputFolder file\n",
    "        self.inputFolder = inputFolder\n",
    "        # outputFolder file\n",
    "        self.outputFolder = outputFolder\n",
    "        # textOutputFolder file\n",
    "        self.textOutputFolder = textOutputFolder\n",
    "        \n",
    "        # Input file\n",
    "        if self.inputFile is None:\n",
    "            self.inputFile = 'test/video1.mp4'\n",
    "        if mode == 'testFile':\n",
    "            if not os.path.exists(self.inputFile):\n",
    "                print(\"ERROR: Image file\", inputFile, \"does not exist!\")\n",
    "                return\n",
    "            \n",
    "        # Output file\n",
    "        if self.outputFile is None:\n",
    "            self.outputFile = 'test/output.jpg'\n",
    "        if mode == 'testFile' and saveAnnotatedImage:\n",
    "            if not os.path.exists(\"/\".join(self.outputFile.split(\"/\")[:-1])):\n",
    "                print(\"ERROR: Image output folder\", \"/\".join(self.outputFile.split(\"/\")[:-1]), \"does not exist!\")\n",
    "                return\n",
    "            \n",
    "        # Text output file\n",
    "        if self.textOutputFile is None:\n",
    "            self.textOutputFile = 'test/outputAnnotations.txt'\n",
    "        if mode == 'testFile' and saveAnnotatedXML:\n",
    "            if not os.path.exists(\"/\".join(self.textOutputFile.split(\"/\")[:-1])):\n",
    "                print(\"ERROR: Text output folder\", \"/\".join(self.textOutputFile.split(\"/\")[:-1]), \"does not exist!\")\n",
    "                return\n",
    "\n",
    "        # Input folder of DB\n",
    "        if self.inputFolder is None:\n",
    "            self.inputFolder = '../VOCdevkit/VOC2007/JPEGImages'\n",
    "        if mode == 'testDB':\n",
    "            if not os.path.exists(inputFolder):\n",
    "                print(\"ERROR: Image input folder\", inputFolder, \"does not exist!\")\n",
    "                return\n",
    "\n",
    "        # Output folder of DB\n",
    "        if self.outputFolder is None:\n",
    "            self.outputFolder = 'VOC2007/test/outputImages/'\n",
    "        if mode == 'testDB' and saveAnnotatedImage:\n",
    "            if not os.path.exists(outputFolder):\n",
    "                print(\"ERROR: Image output folder\", outputFolder, \"does not exist!\")\n",
    "                return\n",
    "\n",
    "        # Text output folder of DB\n",
    "        if self.textOutputFolder is None:\n",
    "            self.textOutputFolder = 'VOC2007/test/outputAnnotations/'\n",
    "        if mode == 'testDB' and saveAnnotatedXML:\n",
    "            if not os.path.exists(textOutputFolder):\n",
    "                print(\"ERROR: Text output folder\", textOutputFolder, \"does not exist!\")\n",
    "                return\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        # Build the YOLO network\n",
    "        self.init_other_vars()\n",
    "        self.build_graph()\n",
    "        \n",
    "        \n",
    "         # If YOLO is to be tested live\n",
    "        if self.mode == 'testLive':\n",
    "            # By default, show annotated images, but don't save\n",
    "            # annotated image or details of predicted objects\n",
    "            # To show image\n",
    "            if self.showImage is None:\n",
    "                self.showImage = True\n",
    "            # To save annotated images\n",
    "            if self.saveAnnotatedImage is None:\n",
    "                self.saveAnnotatedImage = False\n",
    "            # To save annotated XML\n",
    "            if self.saveAnnotatedXML is None:\n",
    "                self.saveAnnotatedXML = False\n",
    "            # Test YOLO live\n",
    "            self.yolo_test_live()\n",
    "            \n",
    "        # Else, if YOLO is to be tested on a file\n",
    "        elif self.mode == 'testFile':\n",
    "            # By default, show annotated image, save the annotated\n",
    "            # image, but don't save details of predicted objects\n",
    "            # To show image\n",
    "            if self.showImage is None:\n",
    "                self.showImage = True\n",
    "            # To save annotated images\n",
    "            if self.saveAnnotatedImage is None:\n",
    "                self.saveAnnotatedImage = True\n",
    "            # To save annotated XML\n",
    "            if self.saveAnnotatedXML is None:\n",
    "                self.saveAnnotatedXML = False\n",
    "            # Test YOLO on self.inputFile\n",
    "            self.yolo_test_file()\n",
    "            \n",
    "        # Else, if YOLO is to be tested on a database\n",
    "        elif self.mode == 'testDB':\n",
    "            # By default, don't show annotated image, but save the\n",
    "            # annotated image and details of predicted objects\n",
    "            # To show image\n",
    "            if self.showImage is None:\n",
    "                self.showImage = False\n",
    "            # To save annotated images\n",
    "            if self.saveAnnotatedImage is None:\n",
    "                self.saveAnnotatedImage = True\n",
    "            # To save annotated XML\n",
    "            if self.saveAnnotatedXML is None:\n",
    "                self.saveAnnotatedXML = True\n",
    "            # Test YOLO on all files in self.inputFolder\n",
    "            self.yolo_test_db()\n",
    "\n",
    "        # Else, if YOLO is to be tested on a video\n",
    "        elif self.mode =='testVideo':\n",
    "            self.yolo_test_video()\n",
    "\n",
    "\n",
    "        else:\n",
    "            # TODO: train mode\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def build_graph(self):\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('Building Yolo Graph....')\n",
    "            \n",
    "        # Reset default graph\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # Input placeholder\n",
    "        self.x = tf.placeholder('float32', [None, 448, 448, 3])\n",
    "        # conv1, pool1\n",
    "        self.conv1 = self.conv_layer(1, self.x, 64, 7, 2)\n",
    "        self.pool1 = self.maxpool_layer(2, self.conv1, 2, 2)\n",
    "        # size reduced to 64x112x112\n",
    "        # conv2, pool2\n",
    "        self.conv2 = self.conv_layer(3, self.pool1, 192, 3, 1)\n",
    "        self.pool2 = self.maxpool_layer(4, self.conv2, 2, 2)\n",
    "        # size reduced to 192x56x56\n",
    "        # conv3, conv4, conv5, conv6, pool3\n",
    "        self.conv3 = self.conv_layer(5, self.pool2, 128, 1, 1)\n",
    "        self.conv4 = self.conv_layer(6, self.conv3, 256, 3, 1)\n",
    "        self.conv5 = self.conv_layer(7, self.conv4, 256, 1, 1)\n",
    "        self.conv6 = self.conv_layer(8, self.conv5, 512, 3, 1)\n",
    "        self.pool3 = self.maxpool_layer(9, self.conv6, 2, 2)\n",
    "        # size reduced to 512x28x28\n",
    "        # conv7 - conv16, pool4\n",
    "        self.conv7 = self.conv_layer(10, self.pool3, 256, 1, 1)\n",
    "        self.conv8 = self.conv_layer(11, self.conv7, 512, 3, 1)\n",
    "        self.conv9 = self.conv_layer(12, self.conv8, 256, 1, 1)\n",
    "        self.conv10 = self.conv_layer(13, self.conv9, 512, 3, 1)\n",
    "        self.conv11 = self.conv_layer(14, self.conv10, 256, 1, 1)\n",
    "        self.conv12 = self.conv_layer(15, self.conv11, 512, 3, 1)\n",
    "        self.conv13 = self.conv_layer(16, self.conv12, 256, 1, 1)\n",
    "        self.conv14 = self.conv_layer(17, self.conv13, 512, 3, 1)\n",
    "        self.conv15 = self.conv_layer(18, self.conv14, 512, 1, 1)\n",
    "        self.conv16 = self.conv_layer(19, self.conv15, 1024, 3, 1)\n",
    "        self.pool4 = self.maxpool_layer(20, self.conv16, 2, 2)\n",
    "        # size reduced to 1024x14x14\n",
    "        # conv17 - conv24\n",
    "        self.conv17 = self.conv_layer(21, self.pool4, 512, 1, 1)\n",
    "        self.conv18 = self.conv_layer(22, self.conv17, 1024, 3, 1)\n",
    "        self.conv19 = self.conv_layer(23, self.conv18, 512, 1, 1)\n",
    "        self.conv20 = self.conv_layer(24, self.conv19, 1024, 3, 1)\n",
    "        self.conv21 = self.conv_layer(25, self.conv20, 1024, 3, 1)\n",
    "        self.conv22 = self.conv_layer(26, self.conv21, 1024, 3, 2)\n",
    "        self.conv23 = self.conv_layer(27, self.conv22, 1024, 3, 1)\n",
    "        self.conv24 = self.conv_layer(28, self.conv23, 1024, 3, 1)\n",
    "        # size reduced to 1024x7x7\n",
    "        # fc1, fc2, fc3\n",
    "        self.fc1 = self.fc_layer(29, self.conv24, 512, flatten=True, linear=False)\n",
    "        self.fc2 = self.fc_layer(30, self.fc1, 4096, flatten=False, linear=False)\n",
    "        self.fc3 = self.fc_layer(31, self.fc2, 1470, flatten=False, linear=True)\n",
    "        \n",
    "        # Run session\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.saver = tf.train.Saver()\n",
    "        self.saver.restore(self.sess, self.weightFile)\n",
    "        # Print\n",
    "        print('Graph built.')\n",
    "        \n",
    "        \n",
    "    def yolo_test_live(self):\n",
    "            \n",
    "        # To capture video\n",
    "        cap = cv2.VideoCapture(0)\n",
    "            \n",
    "        try:\n",
    "            # Capture video in a loop\n",
    "            while(True):\n",
    "                # Capture a frame\n",
    "                ret, frame = cap.read()\n",
    "                # Detect objects\n",
    "                annotatedImage, predictedObjects = self.detect_from_image(frame)\n",
    "                # Show image\n",
    "                if self.showImage:\n",
    "                    cv2.imshow('YOLO Detection', annotatedImage)\n",
    "                    # Press 'q' to quit\n",
    "                    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                        print(\"YOLO stopped by pressing 'q'.\")\n",
    "                        break\n",
    "                \n",
    "                # Save annotated image\n",
    "                if self.saveAnnotatedImage:\n",
    "                    cv2.imwrite('liveImageAnnotations.jpg', annotatedImage)\n",
    "                # Save the parameters of detected objects in xml format\n",
    "                if self.saveAnnotatedXML:\n",
    "                    xmlFileName = 'liveImagePredictions.xml'\n",
    "                    self.save_xml(\"fileName\", xmlFileName, predictedObjects)\n",
    "        \n",
    "        # Press Ctrl+C to quit\n",
    "        except KeyboardInterrupt:\n",
    "             print(\"YOLO stopped via keyboard interrupt.\")\n",
    "        # If video could not be processed\n",
    "        '''except:\n",
    "            print(\"Could not capture/process video...!\")'''\n",
    "        # Roll back\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "            \n",
    "            \n",
    "    def yolo_test_file(self):\n",
    "        \n",
    "        # Detect objects\n",
    "        annotatedImage, predictedObjects = self.detect_from_file(self.inputFile)\n",
    "        # Show image\n",
    "        if self.showImage:\n",
    "            cv2.imshow('YOLO Detection', annotatedImage)\n",
    "            cv2.waitKey(10)\n",
    "        # Save annotated image\n",
    "        if self.saveAnnotatedImage:\n",
    "            cv2.imwrite(self.outputFile, annotatedImage)\n",
    "        # Save the parameters of detected objects in xml format\n",
    "        if self.saveAnnotatedXML:\n",
    "            xmlFileName = os.path.join(self.textOutputFolder, self.outputFile.split('.')[0] + '.xml')\n",
    "            self.save_xml(self.inputFile, xmlFileName, predictedObjects)\n",
    "                    \n",
    "    def yolo_test_video(self):\n",
    "        \"\"\"Test YOLO on a video\"\"\"\n",
    "        # Open the input video, blocking call\n",
    "        \n",
    "        print(self.inputFile)\n",
    "        \n",
    "        inputVideo = cv2.VideoCapture(self.inputFile)\n",
    "\n",
    "        # Get infomration about the input video\n",
    "        codec = int(inputVideo.get(cv2.CAP_PROP_FOURCC))\n",
    "        fps = int(inputVideo.get(cv2.CAP_PROP_FPS))\n",
    "        frameWidth = int(inputVideo.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frameHeight = int(inputVideo.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        # Open the output stream\n",
    "        outputVideo = cv2.VideoWriter(self.outputFile, codec, fps, (frameWidth,frameHeight))\n",
    "        frameIndex = inputVideo.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "        totalFrames = inputVideo.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "        avgGrabTime = 0\n",
    "        avgYoloTime = 0\n",
    "        avgWriteTime = 0\n",
    "\n",
    "        # For each frame in the video\n",
    "        while True:\n",
    "\n",
    "            startTime = time.time()\n",
    "\n",
    "            # Calculate the time it takes to grab a frame\n",
    "            startGrabTime = time.time()\n",
    "            grabbed, frame = inputVideo.read()\n",
    "            endGrabTime = time.time()\n",
    "            avgGrabTime+=(endGrabTime-startGrabTime)\n",
    "\n",
    "\n",
    "            if grabbed:\n",
    "\n",
    "                # Calculate the time it takes to run YOLO pipeline\n",
    "                startYoloTime = time.time()\n",
    "                annotatedFrame, predictedObjects = self.detect_from_image(frame)\n",
    "                endYoloTime = time.time()\n",
    "                avgYoloTime+= ( endYoloTime - startYoloTime)\n",
    "\n",
    "                frameIndex = inputVideo.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "\n",
    "                currentTime = time.time()\n",
    "                elapsedTime = currentTime - startTime\n",
    "                currentFPS = (1)/elapsedTime\n",
    "\n",
    "                #cv2.rectangle(annotatedFrame, (0, 0), (30, 30), (0,0,0), -1)\n",
    "                cv2.putText(annotatedFrame, 'FPS' + ': %.2f' % currentFPS,(15, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255, 255, 255), 2)\n",
    "\n",
    "                # Calculate the time it takes to write an annotated frame to video\n",
    "                startWriteTime = time.time()\n",
    "                outputVideo.write(annotatedFrame)\n",
    "                endWriteTime = time.time()\n",
    "                avgWriteTime +=(endWriteTime - startWriteTime)\n",
    "\n",
    "            else:\n",
    "                inputVideo.set(cv2.CAP_PROP_POS_FRAMES, frameIndex-1)\n",
    "                cv2.waitKey(100)\n",
    "\n",
    "            if frameIndex==totalFrames:\n",
    "                break\n",
    "\n",
    "        inputVideo.release()\n",
    "        outputVideo.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        avgGrabTime/=totalFrames\n",
    "        avgYoloTime/=totalFrames\n",
    "        avgWriteTime/=totalFrames\n",
    "\n",
    "        if self.verbose:\n",
    "            print ('Average time for extracting compressed video frame : %.3f'  %avgGrabTime)\n",
    "            print ('Average time for YOLO object detection : %.3f'  %avgYoloTime )\n",
    "            print ('Average time for writing frame to video : %.3f'  %avgWriteTime)\n",
    "            \n",
    "            \n",
    "    def save_xml(self, inputFileName, outputTextFileName, predictedObjects):\n",
    "\n",
    "        \"\"\"To save XML file with details of predicted object\"\"\"\n",
    "        if self.verbose:\n",
    "            print('Saving xml file', outputTextFileName)\n",
    "        # root element\n",
    "        root = ET.Element(\"annotation\")\n",
    "        # annotation.filename\n",
    "        ET.SubElement(root, \"filename\").text = inputFileName\n",
    "        # For each predicted object\n",
    "        for i in range(len(predictedObjects)):\n",
    "            # annotation.object\n",
    "            predObject = ET.SubElement(root, \"object\")\n",
    "            # annotation.object.name\n",
    "            ET.SubElement(\n",
    "                predObject, \"name\").text = predictedObjects[i][0]\n",
    "            # annotation.object.confidence\n",
    "            ET.SubElement(predObject, \"confidence\").text = str(\n",
    "                predictedObjects[i][5])\n",
    "            # annotation.object.bndBox\n",
    "            bndBox = ET.SubElement(predObject, \"bndBox\")\n",
    "            # annotation.object.bndBox.xmin\n",
    "            ET.SubElement(bndBox, \"xmin\").text = str(\n",
    "                predictedObjects[i][1])\n",
    "            # annotation.object.bndBox.ymin\n",
    "            ET.SubElement(bndBox, \"ymin\").text = str(\n",
    "                predictedObjects[i][2])\n",
    "            # annotation.object.bndBox.xmax\n",
    "            ET.SubElement(bndBox, \"xmax\").text = str(\n",
    "                predictedObjects[i][3])\n",
    "            # annotation.object.bndBox.ymax\n",
    "            ET.SubElement(bndBox, \"ymax\").text = str(\n",
    "                predictedObjects[i][4])\n",
    "        # Making the xml string\n",
    "        xmlString = minidom.parseString(\n",
    "            ET.tostring(root)).toprettyxml(indent=\"   \")\n",
    "        # Saving the xml file\n",
    "        with open(outputTextFileName, 'w') as f:\n",
    "            f.write(xmlString)\n",
    "            \n",
    "    \n",
    "    def init_other_vars(self):\n",
    "\n",
    "        self.endIndexOfClassConditionalProbability = self.numOfGridsIn1D * self.numOfGridsIn1D * self.numOfClasses\n",
    "        self.endIndexOfObjectProbability = self.endIndexOfClassConditionalProbability + self.numOfGridsIn1D*self.numOfGridsIn1D*self.numOfBoxesPerGrid\n",
    "        \n",
    "        # Class Conditional Probability: P(class | object),\n",
    "        self.classConditionalProbability = np.zeros([self.numOfGridsIn1D, self.numOfGridsIn1D, self.numOfClasses])\n",
    "        # P(object): Object probability, i.e. the probability of an\n",
    "        self.objectProbability = np.zeros([self.numOfGridsIn1D, self.numOfGridsIn1D, self.numOfBoxesPerGrid])\n",
    "        \n",
    "        # Box data (x, y, w, h)\n",
    "        self.boxData = np.zeros([self.numOfGridsIn1D, self.numOfGridsIn1D, self.numOfBoxesPerGrid, 4])\n",
    "        \n",
    "        # Offset to add to x and y values to convert from within-grid\n",
    "        # coordinates to image coordinates\n",
    "        self.offsetY = np.tile(np.arange(self.numOfGridsIn1D)[:, np.newaxis, np.newaxis],(1, self.numOfGridsIn1D, self.numOfBoxesPerGrid))\n",
    "        self.offsetX = np.transpose(self.offsetY, (1, 0, 2))\n",
    "        \n",
    "        # Most probable classes per grid\n",
    "        self.maxProbableClasses = np.zeros([self.numOfGridsIn1D, self.numOfGridsIn1D, self.numOfBoxesPerGrid])\n",
    "        \n",
    "        # Probabilities of most probable classes per grid\n",
    "        self.maxProbableClassProbabilities = np.zeros([self.numOfGridsIn1D, self.numOfGridsIn1D, self.numOfBoxesPerGrid])\n",
    "        \n",
    "        # The probability of an object present, and it being each class\n",
    "        self.objectClassProbability = np.zeros([self.numOfGridsIn1D, self.numOfGridsIn1D, self.numOfBoxesPerGrid, self.numOfClasses])\n",
    "\n",
    "    def detect_from_file(self, fileName):\n",
    "\n",
    "        if self.verbose:\n",
    "            print('Detecting object from :', fileName)\n",
    "        # Read image from file\n",
    "        imageMatrix = cv2.imread(fileName)\n",
    "        # Detect objects in image\n",
    "        return self.detect_from_image(imageMatrix)\n",
    "\n",
    "    def detect_from_image(self, imageMatrix):\n",
    "\n",
    "        image = imageMatrix\n",
    "        self.imageHeight, self.imageWidth, _ = imageMatrix.shape\n",
    "        # Resize the image as required by network\n",
    "        # Make image shape 1x448x448x3\n",
    "        # Normalize the image values between -1 and 1\n",
    "        imageMatrix = np.expand_dims(np.asarray(cv2.cvtColor(cv2.resize(imageMatrix, (448, 448)), cv2.COLOR_BGR2RGB), dtype='float32')/255.*2. - 1., axis=0)\n",
    "        # Run image through network and get its output\n",
    "        netOutput = self.sess.run(self.fc3, feed_dict={self.x: imageMatrix})\n",
    "        # Figure out the object classes and bounding boxes from the\n",
    "        # network output\n",
    "        self.result = self.interpret_output(netOutput)\n",
    "        # Make an annotated image with the classes and bounding boxes\n",
    "        return self.annotate_image(image, self.result)\n",
    "\n",
    "    \n",
    "    def interpret_output(self, netOutput):\n",
    "     \n",
    "        # Class Conditional Probability: P(class | object),\n",
    "        # i.e. assuming there is an object in the grid being considered,\n",
    "        # what is the probability the object belongs to each class\n",
    "        self.classConditionalProbability = np.reshape(netOutput[:, :self.endIndexOfClassConditionalProbability], [self.numOfGridsIn1D, self.numOfGridsIn1D, self.numOfClasses])\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"classConditionalProbability.\")\n",
    "        # P(object): Object probability, i.e. the probability of an\n",
    "        # object in each bounding box in each grid\n",
    "        self.objectProbability = np.reshape(netOutput[:,self.endIndexOfClassConditionalProbability:self.endIndexOfObjectProbability],[self.numOfGridsIn1D, self.numOfGridsIn1D, self.numOfBoxesPerGrid])\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"objectProbability.\")\n",
    "            \n",
    "        # objectClassProbability: P(class | object) * P(object), i.e.\n",
    "        # the probability of an object present, and it being each class\n",
    "        # Equivalent to:\n",
    "        #for i in range(self.numOfBoxesPerGrid):\n",
    "        #    for j in range(self.numOfClasses):\n",
    "        #        self.objectClassProbability[:, :, i, j] = np.multiply(\n",
    "        #            self.objectProbability[:, :, i],\n",
    "        #            self.classConditionalProbability[:, :, j]\n",
    "        #            )\n",
    "        # Also equivalent to:\n",
    "        # for i in range(self.numOfGridsIn1D):\n",
    "        #     for j in range(self.numOfGridsIn1D):\n",
    "        #         self.objectClassProbability[i, j] = np.outer(\n",
    "        #             self.objectProbability[i, j, :],\n",
    "        #             self.classConditionalProbability[i, j, :]\n",
    "        #             )\n",
    "        # Or:\n",
    "        self.objectClassProbability = np.einsum('...i, ...j', self.objectProbability, self.classConditionalProbability, out=self.objectClassProbability)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"objectClassProbability.\")\n",
    "        \n",
    "        # (x, y, w, h) == (<left> <top> <right> <bottom>) of the\n",
    "        # numOfBoxesPerGrid bounding boxes predicted by the network\n",
    "        \n",
    "        self.boxData = np.reshape(netOutput[:, self.endIndexOfObjectProbability:],[self.numOfGridsIn1D, self.numOfGridsIn1D, self.numOfBoxesPerGrid, 4])\n",
    "        # Changing x <left> and y <top> coordinates from within-grid\n",
    "        # coordinates to image coordinates\n",
    "        \n",
    "        self.boxData[:, :, :, 0] = 1. * (self.boxData[:, :, :, 0]+self.offsetX) * self.imageWidth / self.numOfGridsIn1D\n",
    "        self.boxData[:, :, :, 1] = 1. * (self.boxData[:, :, :, 1]+self.offsetY) * self.imageHeight / self.numOfGridsIn1D\n",
    "        \n",
    "        # Changing width and height from model representation to image\n",
    "        # representation, square root of the width and height is predicted\n",
    "        # because small error in small boxes matter much more than small errors\n",
    "        # in large boxes\n",
    "        self.boxData[:, :, :, 2] = self.imageWidth * np.multiply(self.boxData[:, :, :, 2], self.boxData[:, :, :, 2])\n",
    "        self.boxData[:, :, :, 3] = self.imageHeight * np.multiply(self.boxData[:, :, :, 3], self.boxData[:, :, :, 3]\n",
    "                                                    )\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"boxData.\")\n",
    "        \n",
    "        # Find out the index of the class with maximum probability for\n",
    "        # every object/bounding box\n",
    "        self.maxProbableClasses = np.argmax(self.objectClassProbability, axis=3)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"maxProbableClasses.\")\n",
    "        \n",
    "        # Find out the probability value of these max classes\n",
    "        self.maxProbableClassProbabilities = np.max(self.objectClassProbability, axis=3)\n",
    "        if self.debug:\n",
    "            print(\"maxProbableClassProbabilities.\")\n",
    "        \n",
    "        # Eliminate those objects whose class probabilities are lesser\n",
    "        # than minClassProbability\n",
    "        thresholdedClassesIndex = np.where(self.maxProbableClassProbabilities >= self.minClassProbability)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"thresholdedClassesIndex.\")\n",
    "        \n",
    "        # The classes\n",
    "        thresholdedClasses = self.maxProbableClasses[thresholdedClassesIndex]\n",
    "        if self.debug:\n",
    "            print(\"thresholdedClasses.\")\n",
    "        \n",
    "        # The class probabilities\n",
    "        thresholdedClassProbabilities = self.maxProbableClassProbabilities[thresholdedClassesIndex]\n",
    "        if self.debug:\n",
    "            print(\"thresholdedClassProbabilities.\")\n",
    "        # Find out the boxes corresponding to the filtered objects\n",
    "        thresholdedBoxes = self.boxData[thresholdedClassesIndex[0],thresholdedClassesIndex[1],thresholdedClassesIndex[2]]\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"thresholdedBoxes.\")\n",
    "        \n",
    "        # Sort the boxes and classes based on probabilities\n",
    "        sortOrder = np.argsort(thresholdedClassProbabilities)[::-1]\n",
    "        if self.debug:\n",
    "            print(\"sortOrder.\")\n",
    "        thresholdedClassProbabilities = thresholdedClassProbabilities[sortOrder]\n",
    "        thresholdedBoxes = thresholdedBoxes[sortOrder]\n",
    "        thresholdedClasses = thresholdedClasses[sortOrder]\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"thresholdedClasses.\")\n",
    "        # Non-maximum supression\n",
    "        for box1 in range(len(thresholdedClassProbabilities)):\n",
    "            if thresholdedClassProbabilities[box1] == 0.:\n",
    "                continue\n",
    "            for box2 in range(box1 + 1, len(thresholdedClassProbabilities)):\n",
    "                if self.iou(thresholdedBoxes[box1], thresholdedBoxes[box2]) > self.iouThreshold:\n",
    "                    thresholdedClassProbabilities[box2] = 0.\n",
    "        \n",
    "        # Non-suppressed boxes\n",
    "        nonSuppressedIndex = np.where(thresholdedClassProbabilities > 0)\n",
    "        thresholdedClassProbabilities = thresholdedClassProbabilities[nonSuppressedIndex]\n",
    "        thresholdedBoxes = thresholdedBoxes[nonSuppressedIndex]\n",
    "        thresholdedClasses = thresholdedClasses[nonSuppressedIndex]\n",
    "        if self.debug:\n",
    "            print(\"thresholdedClasses[nonSuppressedIndex].\")\n",
    "        # Results\n",
    "        result = []\n",
    "        for i in range(len(thresholdedClasses)):\n",
    "            result.append([self.classes[thresholdedClasses[i]],\n",
    "                                        thresholdedBoxes[i][0],\n",
    "                                        thresholdedBoxes[i][1],\n",
    "                                        thresholdedBoxes[i][2],\n",
    "                                        thresholdedBoxes[i][3],\n",
    "                                        thresholdedClassProbabilities[i]])\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def annotate_image(self, image, results):\n",
    "        \"\"\" Annotate image with results from netOutput\"\"\"\n",
    "        predictedObjects = []\n",
    "        for i in range(len(results)):\n",
    "            objectParameters = []\n",
    "            x = int(results[i][1])\n",
    "            y = int(results[i][2])\n",
    "            w = int(results[i][3])\n",
    "            h = int(results[i][4])\n",
    "            # print(x, y, w, h, results[i][0])\n",
    "            imageHeight, imageWidth, _ = image.shape\n",
    "            w = w // 2\n",
    "            h = h // 2\n",
    "            # change to truncate boxes which go outside the image\n",
    "            xmin, xmax, ymin, ymax = 0, 0, 0, 0\n",
    "            xmin = 3 if not max(x - w, 0) else (x - w)\n",
    "            xmax = imageWidth - 3 if not min(x + w - imageWidth, 0) \\\n",
    "                                    else (x + w)\n",
    "            ymin = 1 if not max(y - h, 0) else (y - h)\n",
    "            ymax = imageHeight - 3 if not min(y + h - imageHeight, 0) \\\n",
    "                                    else (y + h)\n",
    "            if self.verbose:\n",
    "                print('Class : ' + results[i][0] + ', [x, y, w, h] [' +\n",
    "                    str(x) + ', ' + str(y) + ', ' + str(w) + ', ' + str(h) +\n",
    "                    '] Confidence : ' + str(results[i][5]))\n",
    "\n",
    "            # Each class must have a unique color\n",
    "            color = tuple([(j * (1+self.classes.index(results[i][0])) % 255) \\\n",
    "                    for j in self.seed])\n",
    "            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "            if ymin <= 20:\n",
    "                cv2.rectangle(\n",
    "                    image, (xmin, ymin), (xmax, ymin + 20), color, -1\n",
    "                    )\n",
    "                cv2.putText(\n",
    "                    image, results[i][0] + ': %.2f' % results[i][5],\n",
    "                    (xmin+5, ymin+15), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                    (255, 255, 255), 2\n",
    "                    )\n",
    "            else:\n",
    "                cv2.rectangle(image, (xmin, ymin), (xmax, ymin-20), color, -1)\n",
    "                cv2.putText(\n",
    "                    image, results[i][0] + ': %.2f' % results[i][5],\n",
    "                    (xmin+5, ymin-8), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                    (255, 255, 255), 2\n",
    "                    )\n",
    "            objectParameters = [\n",
    "                results[i][0], xmin, ymin, xmax, ymax, results[i][5]\n",
    "                ]\n",
    "            predictedObjects.append(objectParameters)\n",
    "        return image, predictedObjects\n",
    "        # if self.outputFile:\n",
    "        #    cv2.imwrite(self.outputFile,image)\n",
    "        \n",
    "    def iou(self, boxA, boxB):\n",
    "        \"\"\"Calculate IoU between boxA and boxB\"\"\"\n",
    "        intersectionX = max(0, min(boxA[0] + boxA[2]*0.5, boxB[0] + boxB[2]*0.5) - max(boxA[0] - boxA[2]*0.5,boxB[0] - boxB[2]*0.5))\n",
    "        intersectionY = max(0, min(boxA[1] + boxA[3]*0.5, boxB[1] + boxB[3]*0.5) - max(boxA[1] - boxA[3]*0.5,boxB[1] - boxB[3]*0.5))\n",
    "        \n",
    "        intersection = intersectionX * intersectionY\n",
    "        union = boxA[2]*boxA[3] + boxB[2]*boxB[3] - intersection\n",
    "        # print(intersection, union, intersection / union)\n",
    "        return intersection / union\n",
    "        \n",
    "    def iou_train(self, boxA, boxB, realBox):\n",
    "        \"\"\"\n",
    "        Calculate IoU between boxA and realBox\n",
    "        Calculate the IoU in training phase, to get the box (out of N\n",
    "            boxes per grid) responsible for ground truth box\n",
    "        \"\"\"\n",
    "        iou1 = tf.reshape(iou_train_unit(boxA, realBox), [-1, 7, 7, 1])\n",
    "        iou2 = tf.reshape(iou_train_unit(boxB, realBox), [-1, 7, 7, 1])\n",
    "        return tf.concat([iou1, iou2], 3)\n",
    "\n",
    "    def iou_train_unit(self, boxA, realBox):\n",
    "        \"\"\"\n",
    "        Calculate IoU between boxA and realBox\n",
    "        \"\"\"\n",
    "        # make sure that the representation of box matches input\n",
    "        intersectionX = tf.minimum(\n",
    "            boxA[:, :, :, 0] + 0.5*boxA[:, :, :, 2],\n",
    "            realBox[:, :, :, 0] + 0.5*realBox[:, :, :, 2]\n",
    "            ) - tf.maximum(\n",
    "                    boxA[:, :, :, 0] - 0.5*boxA[:, :, :, 2],\n",
    "                    realBox[:, :, :, 0] - 0.5*realBox[:, :, :, 2]\n",
    "                    )\n",
    "        intersectionY = tf.minimum(\n",
    "            boxA[:, :, :, 1] + 0.5*boxA[:, :, :, 3],\n",
    "            realBox[:, :, :, 1] + 0.5*realBox[:, :, :, 3]\n",
    "            ) - tf.maximum(\n",
    "                        boxA[:, :, :, 1] - 0.5*boxA[:, :, :, 3],\n",
    "                        realBox[:, :, :, 1] - 0.5*realBox[:, :, :, 3]\n",
    "                        )\n",
    "        intersection = tf.multiply(\n",
    "            tf.maximum(0, intersectionX), tf.maximum(0, intersectionY)\n",
    "            )\n",
    "        union = tf.subtract(\n",
    "                    tf.multiply(\n",
    "                        boxA[:, :, :, 1], boxA[:, :, :, 3]) + tf.multiply(\n",
    "                            realBox[:, :, :, 1], realBox[:, :, :, 3]\n",
    "                            ),\n",
    "                        intersection\n",
    "                        )\n",
    "        iou = tf.divide(intersection, union)\n",
    "        return iou\n",
    "\n",
    "    # TODO\n",
    "    def train_network(self):\n",
    "        \"\"\"\n",
    "        Determine which bounding box is responsible for prediction.\n",
    "        Save the weights after each epoch.\n",
    "        \"\"\"\n",
    "        if self.trainData:\n",
    "            if self.verbose:\n",
    "                print('Started training...')\n",
    "\n",
    "            for epoch in range(135):\n",
    "                pass\n",
    "                # save the model\n",
    "        else:\n",
    "            if self.verbose:\n",
    "                print('No train data available')\n",
    "\n",
    "    def calculate_loss_function(self, predicted, groundTruth):\n",
    "        \"\"\"\n",
    "        Calculate the total loss for gradient descent.\n",
    "        For each ground truth object, loss needs to be calculated.\n",
    "        It is assumed that each image consists of only one object.\n",
    "        Predicted\n",
    "        0-19 CLass prediction\n",
    "        20-21 Confidence that objects exist in bbox1 or bbox2 of grid\n",
    "        22-29 Coordinates for bbo1, followed by those of bbox2\n",
    "        Real\n",
    "        0-19 Class prediction (One-Hot Encoded)\n",
    "        20-23 Ground truth coordinates for that box\n",
    "        24-72 Cell has an object/no object (Only one can be is 1)\n",
    "        \"\"\"\n",
    "        predictedParameters = np.reshape(\n",
    "            predicted, [-1, self.numOfGridsIn1D, self.numOfGridsIn1D, 30])\n",
    "        predictedClasses = predictedParameters[:, :, :, :20]\n",
    "        predictedObjectConfidence = predictedParameters[:, :, :, 20:22]\n",
    "        predictedBoxes = predictedParameters[:, :, :, 22:]\n",
    "        groundTruthClasses = np.reshape(groundTruth[:, :20], [-1, 1, 1, 20])\n",
    "        groundTruthBoxes = np.reshape(groundTruth[:, 20:24], [-1, 1, 1, 4])\n",
    "        groundTruthGrid = np.reshape(groundTruth[:, 24:], [-1, 7, 7, 1])\n",
    "        predictedFirstBoxes = predictedBoxes[:, :, :, :4]\n",
    "        predictedSecondBoxes = predictedBoxes[:, :, :, 5:]\n",
    "        # Calulate loss along the 4th axis, localFirstBoxes -1x7x7x1\n",
    "        # Think there should be a simpler method to do this\n",
    "        lossFirstBoxes = tf.reduce_sum(\n",
    "            tf.square(predictedFirstBoxes - groundTruthBoxes), 3)\n",
    "        lossSecondBoxes = tf.reduce_sum(\n",
    "            tf.square(predictedSecondBoxes - groundTruthBoxes), 3)\n",
    "        # Computing which box (bbox1 or bbox2) is responsible for\n",
    "        # detection\n",
    "        IOU = iou_train(predictedFirstBoxes,\n",
    "                       predictedSecondBoxes, groundTruthBoxes)\n",
    "        responsbileBox = tf.greater(IOU[:, :, :, 0], IOU[:, :, :, 1])\n",
    "        # Suppose it is known which iou is greater,\n",
    "        # coordinate loss (loss due to difference in coordinates of\n",
    "        # predicted-responsible and real box)\n",
    "        coordinateLoss = tf.where(\n",
    "            responsibleBox, lossFirstBoxes, lossSecondBoxes)\n",
    "        # why do we need to reshape it\n",
    "        coordinateLoss = tf.reshape(coordinateLoss, [-1, 7, 7, 1])\n",
    "        # count the loss only if the object is in the groundTruth grid\n",
    "        # gives a sparse -1x7x7x1 matrix, only one element would be nonzero in\n",
    "        # each slice\n",
    "        coorinateLoss = self.lambdaCoordinate * \\\n",
    "            tf.multiply(groundTruthGrid, coordinateLoss)\n",
    "        # object loss (loss due to difference in object confidence)\n",
    "        # only take the objectLoss of the predicted grid with higher IoU is\n",
    "        # responsible for the object\n",
    "        objectLoss = tf.square(predictedObjectConfidence - groundTruthGrid)\n",
    "        objectLoss = tf.where(responsibleBox, objectLoss[\n",
    "                              :, :, :, 0], objectLoss[:, :, :, 1])\n",
    "        tempObjectLoss = tf.reshape(objectLoss, [-1, 7, 7, 1])\n",
    "        objectLoss = tf.multiply(groundTruthGrid, tempObjectLoss)\n",
    "        # class loss (loss due to misjudgement in class of the object\n",
    "        # detected\n",
    "        classLoss = tf.square(predictedClasses - groundTruthClasses)\n",
    "        classLoss = tf.reduce_sum(\n",
    "            tf.mul(groundTruthGrid, classLoss), reduction_indices=3)\n",
    "        classLoss = tf.reshape(classLoss, [-1, 7, 7, 1])\n",
    "        # no-object loss, decrease the confidence where there is no\n",
    "        # object in the ground truth\n",
    "        noObjectLoss = self.lambdaNoObject * \\\n",
    "            tf.multiply(1 - groundTruthGrid, tempObjectLoss)\n",
    "        # total loss\n",
    "        totalLoss = coordinateLoss + objectLoss + classLoss + noObjectLoss\n",
    "        totalLoss = tf.reduce_mean(tf.reduce_sum(\n",
    "            totalLoss, reduction_indeces=[1, 2, 3]), reduction_indices=0)\n",
    "        return totalLoss\n",
    "    \n",
    "    # Conv layer\n",
    "    def conv_layer(self, index, inputMatrix, numOfFilters, sizeOfFilter,\n",
    "        stride):\n",
    "        \"\"\"\n",
    "        Convolve inputMatrix with filters\n",
    "        Input\n",
    "        index : index of the layer within the network\n",
    "        inputMatrix : self-Explainatory, the input\n",
    "        numberOfFilters : number of channel outputs\n",
    "        sizeOfFilter : defines the receptive field of a neuron\n",
    "        stride : self-Exmplainatory, pixels to skip\n",
    "        Output\n",
    "        Matrix the size of input[0]xinput[1]xnoOfFilters\n",
    "        \"\"\"\n",
    "        numOfChannels = inputMatrix.get_shape()[3]\n",
    "        # int with numberOfChannels\n",
    "        weight = tf.Variable(tf.truncated_normal(\n",
    "            [sizeOfFilter, sizeOfFilter, int(numOfChannels), numOfFilters],\n",
    "            stddev=0.1))\n",
    "        bias = tf.Variable(tf.constant(0.1, shape=[numOfFilters]))\n",
    "        padSize = sizeOfFilter // 2\n",
    "        paddedInput = tf.pad(\n",
    "            inputMatrix, ([[0, 0], [padSize, padSize], [padSize, padSize],\n",
    "                           [0, 0]]))\n",
    "        conv = tf.nn.conv2d(paddedInput, weight, strides=[\n",
    "                            1, stride, stride, 1], padding='VALID',\n",
    "                            name=str(index) + '_conv')\n",
    "        conv_bias = tf.add(conv, bias, name=str(index) + '_conv')\n",
    "        if self.verbose:\n",
    "            print(' Layer %d Type: Conv Size: %dx%d Stride: %d No.Filters: %d '\n",
    "                'Input Channels : %d' % (index, sizeOfFilter, sizeOfFilter,\n",
    "                                        stride, numOfFilters, numOfChannels))\n",
    "        # leaky relu as mentioned in YOLO paper\n",
    "        return tf.maximum(self.leakyReLUAlpha * conv_bias, conv_bias,\n",
    "                          name=str(index) + '_leaky_relu')\n",
    "\n",
    "    def maxpool_layer(self, index, inputMatrix, sizeOfFilter, stride):\n",
    "        \"\"\"\n",
    "        Pool inputMatrix into lesser dimensions\n",
    "        Input\n",
    "        index : index of the layer within the network\n",
    "        inputMatrix : self-Explainatory, the input\n",
    "        sizeOfFilter : defines the receptive field of a neuron\n",
    "        stride : self-Exmplainatory, pixels to skip\n",
    "        Output\n",
    "        Matrix the size of (input0/stride)x(input1/stride)xnoOfFilters\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print(' Layer %d Type: Maxpool Size: %dx%d Stride: %d' %\n",
    "                  (index, sizeOfFilter, sizeOfFilter, stride))\n",
    "        maxpool = tf.nn.max_pool(inputMatrix,\n",
    "                                 ksize=[1, sizeOfFilter, sizeOfFilter, 1],\n",
    "                                 strides=[1, sizeOfFilter, sizeOfFilter, 1],\n",
    "                                 padding='SAME', name=str(index) + '_maxpool')\n",
    "        return maxpool\n",
    "\n",
    "    def fc_layer(self, index, inputMatrix, outputNodes, flatten, linear):\n",
    "        \"\"\"\n",
    "        Fully connected neural layer between inputMatrix and output\n",
    "        Input\n",
    "        index : index of the layer within the network\n",
    "        inputMatrix : self-Explainatory, the input\n",
    "        sizeOfFilter : defines the receptive field of a neuron\n",
    "        stride : self-Exmplainatory, pixels to skip\n",
    "        Output\n",
    "        Matrix the size of (input0/stride)x(input1/stride)xnoOfFilters\n",
    "        \"\"\"\n",
    "        inputShape = inputMatrix.get_shape().as_list()\n",
    "        if flatten:\n",
    "            # flatten the matrix\n",
    "            inputDimension = inputShape[1] * inputShape[2] * inputShape[3]\n",
    "            # change it to the input as required by fully connected layer\n",
    "            inputMatrixAdjust = tf.transpose(inputMatrix, (0, 3, 1, 2))\n",
    "            inputMatrixAdjust = tf.reshape(\n",
    "                inputMatrixAdjust, [-1, inputDimension])\n",
    "        else:\n",
    "            inputDimension = inputShape[1]\n",
    "            inputMatrixAdjust = inputMatrix\n",
    "        # W, b\n",
    "        weight = tf.Variable(tf.truncated_normal(\n",
    "            [inputDimension, outputNodes], stddev=0.1))\n",
    "        bias = tf.Variable(tf.constant(0.1, shape=[outputNodes]))\n",
    "        if self.verbose:\n",
    "            print(' Layer %d Type: FullyConnected InSize: %d OutSize %d '\n",
    "              'Linear: %d' % (index, inputDimension, outputNodes, int(linear)))\n",
    "        # linear or leaky relu activation\n",
    "        if linear:\n",
    "            return tf.add(tf.matmul(inputMatrixAdjust, weight), bias,\n",
    "                          name=str(index) + '_fc')\n",
    "        else:\n",
    "            answer = tf.add(tf.matmul(inputMatrixAdjust, weight), bias,\n",
    "                            name=str(index) + '_fc')\n",
    "            return tf.maximum(self.leakyReLUAlpha * answer, answer,\n",
    "                              name=str(index) + '_fc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    yolo = Yolo(mode='testLive',\n",
    "                inputFolder='',\n",
    "                saveAnnotatedImage=True,\n",
    "                saveAnnotatedXML=True,\n",
    "                textOutputFolder='',\n",
    "                iouThreshold=0.2,\n",
    "                verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from weights/YOLO_small.ckpt\n",
      "Graph built.\n",
      "YOLO stopped by pressing 'q'.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
